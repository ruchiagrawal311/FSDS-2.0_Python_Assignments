{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af4aeea9",
   "metadata": {},
   "source": [
    "# 1. In what modes should the PdfFileReader() and PdfFileWriter() File objects will be opened?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68812184",
   "metadata": {},
   "source": [
    "<b>Ans: </b>For PdfFileReader() file objects should be opened in rb -> read binary mode, Whereas for PdfFileWriter() file objects should be opened in wb -> write binary mode."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7ad569",
   "metadata": {},
   "source": [
    "# 2. From a PdfFileReader object, how do you get a Page object for page 5?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16b79d7",
   "metadata": {},
   "source": [
    "<b>Ans: </b>PdfFileReader class provides a method called getPage(page_no) to get a page object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d61f5abc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: PyPDF2 in c:\\users\\ridhi\\anaconda3\\lib\\site-packages (3.0.1)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: typing_extensions>=3.10.0.0 in c:\\users\\ridhi\\anaconda3\\lib\\site-packages (from PyPDF2) (4.3.0)\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c9ca95c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyPDF2 import PdfReader\n",
    "\n",
    "# Open the PDF file\n",
    "pdf_file = open('Growth and Development.pdf', 'rb')\n",
    "\n",
    "# Create a PdfReader object\n",
    "pdf_reader = PdfReader(pdf_file)\n",
    "\n",
    "# Get the Page object for page 5\n",
    "page_number = 4  # Zero-based index\n",
    "page = pdf_reader.pages[page_number]\n",
    "\n",
    "# Close the PDF file\n",
    "pdf_file.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8af64b",
   "metadata": {},
   "source": [
    "# 3. What PdfFileReader variable stores the number of pages in the PDF document?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1692825",
   "metadata": {},
   "source": [
    "<b>Ans: </b>If a PdfFileReader objectâ€™s PDF is encrypted with the password swordfish and you're not aware of it. first read the Pdf using the PdfFileReader Class. PdfFileReader class provides a attribute called isEncrypted to check whether a pdf is encrypted or not. the method returns true if a pdf is encrypted and vice versa.\n",
    "if pdf is encrypted use the decrypt() method provided by PdfFileReader class first then try to read the contents/pages of the pdf, else PyPDF2 will raise the following error PyPDF2.utils.PdfReadError: file has not been decrypted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8ea6242f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of pages: 529\n"
     ]
    }
   ],
   "source": [
    "#Example \n",
    "from PyPDF2 import PdfReader\n",
    "\n",
    "# Open the PDF file\n",
    "pdf_file = open('Growth and Development.pdf', 'rb')\n",
    "\n",
    "# Create a PdfReader object\n",
    "pdf_reader = PdfReader(pdf_file)\n",
    "\n",
    "# Get the number of pages in the PDF document\n",
    "num_pages = len(pdf_reader.pages)\n",
    "\n",
    "# Print the number of pages\n",
    "print(f\"Number of pages: {num_pages}\")\n",
    "\n",
    "# Close the PDF file\n",
    "pdf_file.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a603343c",
   "metadata": {},
   "source": [
    "# 4. If a PdfFileReader objectâ€™s PDF is encrypted with the password swordfish, what must you do before you can obtain Page objects from it?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e71ab5",
   "metadata": {},
   "source": [
    "<b>Ans: </b>If a PdfFileReader objectâ€™s PDF is encrypted with the password swordfish and you're not aware of it. first read the Pdf using the PdfFileReader Class. PdfFileReader class provides a attribute called isEncrypted to check whether a pdf is encrypted or not. the method returns true if a pdf is encrypted and vice versa.\n",
    "if pdf is encrypted use the decrypt() method provided by PdfFileReader class first then try to read the contents/pages of the pdf, else PyPDF2 will raise the following error PyPDF2.utils.PdfReadError: file has not been decrypted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d1f173dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example\n",
    "from PyPDF2 import PdfReader\n",
    "\n",
    "# Open the PDF file\n",
    "pdf_file = open('Growth and Development.pdf', 'rb')\n",
    "\n",
    "# Create a PdfReader object\n",
    "pdf_reader = PdfReader(pdf_file)\n",
    "\n",
    "# Check if the PDF is encrypted\n",
    "if pdf_reader.is_encrypted:\n",
    "    # Decrypt the PDF with the password\n",
    "    pdf_reader.decrypt('swordfish')\n",
    "\n",
    "# Get the Page object for a specific page\n",
    "page_number = 4  # Zero-based index\n",
    "page = pdf_reader.pages[page_number]\n",
    "\n",
    "pdf_file.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83fcd29",
   "metadata": {},
   "source": [
    "# 5. What methods do you use to rotate a page?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e59fe7c9",
   "metadata": {},
   "source": [
    "<b>Ans: </b>PyPDF2 Package provides 2 methods to rotate a page:\n",
    "\n",
    "1. rotateClockWise() -> For Clockwise rotation<br>\n",
    "2. rotateCounterClockWise() -> For Counter Clockwise rotation\n",
    "\n",
    "The PyPDF2 package only allows you to rotate a page in increments of 90 degrees. You will receive an AssertionError otherwise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e8b8f5",
   "metadata": {},
   "source": [
    "# 6. What is the difference between a Run object and a Paragraph object?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0beee444",
   "metadata": {},
   "source": [
    "<b>Ans: </b>The structure of a document is represented by three different data types in python-Docx. At the highest level, a Document object represents the entire document. The Document object contains a list of Paragraph objects for the paragraphs in the document. (A new paragraph begins whenever the user presses ENTER or RETURN while typing in a Word document.) Each of these Paragraph objects contains a list of one or more Run objects.\n",
    "\n",
    "The text in a Word document is more than just a string. It has font, size, color, and other styling information associated with it. A style in Word is a collection of these attributes. A Run object is a contiguous run of text with the same style. A new Run object is needed whenever the text style changes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29bf727b",
   "metadata": {},
   "source": [
    "# 7. How do you obtain a list of Paragraph objects for a Document object thatâ€™s stored in a variable named doc?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec68a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install python-docx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "517c734a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python\n",
      "Total Marks: 100\n",
      "Each question 10 marks\n",
      "Question 1: -\n",
      "\n",
      "Write a program that takes a string as input, and counts the frequency of each word in the string, there might be repeated characters in the string. Your task is to find the highest frequency and returns the length of the highest-frequency word.\n",
      "\n",
      "\n",
      "Note - You have to write at least 2 additional test cases in which your program will run successfully and provide an explanation for the same.\n",
      "Example input - string = â€œwrite write write all the number from from from 1 to 100â€ Example output - 5\n",
      "Explanation - From the given string we can note that the most frequent words are â€œwriteâ€ and â€œfromâ€ and the maximum value of both the values is â€œwriteâ€ and its corresponding length is 5\n",
      "\n",
      "\n",
      "\n",
      "Question 2: -\n",
      "Consider a string to be valid if all characters of the string appear the same number of times. It is also valid if he can remove just one character at the index in the string, and the remaining characters will occur the same number of times. Given a string, determine if it is valid. If so, return YES , otherwise return NO .\n",
      "\n",
      "\n",
      "Note - You have to write at least 2 additional test cases in which your program will run successfully and provide an explanation for the same.\n",
      "Example input 1 - s = â€œabcâ€. This is a valid string because frequencies are { â€œaâ€: 1, â€œbâ€: 1, â€œcâ€: 1 } Example output 1- YES\n",
      "Example input 2 - s â€œabccâ€. This string is not valid as we can remove only 1 occurrence of â€œcâ€. That leaves character frequencies of { â€œaâ€: 1, â€œbâ€: 1 , â€œcâ€: 2 }\n",
      "Example output 2 - NO\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Question 3: -\n",
      "Write a program, which would download the data from the provided link, and then read the data and convert that into properly structured data and return it in Excel format.\n",
      "Note - Write comments wherever necessary explaining the code written.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Link - https://raw.githubusercontent.com/Biuni/PokemonGO-Pokedex/master/pokedex.json\n",
      "\n",
      "Data Attributes - id: Identification Number - int num: Number of the\n",
      "\n",
      "PokÃ©mon in the official PokÃ©dex - int name: PokÃ©mon name -\n",
      "string img: URL to an image of this PokÃ©mon - string type:\n",
      "PokÃ©mon type -string height: PokÃ©mon height - float\n",
      "\n",
      "weight: PokÃ©mon weight - float candy: type of candy used to evolve PokÃ©mon or given\n",
      "when transferred - string candy_count: the amount of candies required to evolve\n",
      "- int\n",
      "egg: Number of kilometers to travel to hatch the egg - float spawn_chance:\n",
      "Percentage of spawn chance (NEW) - float avg_spawns: Number of this pokemon on 10.000 spawns (NEW) - int\n",
      "spawn_time: Spawns most active at the time on this field. Spawn times are the same for all time zones and are expressed in local time. (NEW) - â€œminutes: secondsâ€ multipliers: Multiplier of Combat Power (CP) for calculating the CP after evolution See below - list of int weakness: Types of\n",
      "PokÃ©mon this PokÃ©mon is weak to - list of strings next_evolution: Number and Name of successive evolutions of PokÃ©mon - list of dict prev_evolution: Number and Name of previous evolutions of PokÃ©mon - - list of dict\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Question 4 -\n",
      "Write a program to download the data from the link given below and then read the data and convert the into the proper structure and return it as a CSV file.\n",
      "Link - https://data.nasa.gov/resource/y77d-th95.json\n",
      "Note - Write code comments wherever needed for code understanding.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Sample Data -\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Excepted Output Data Attributes\n",
      "\n",
      "\n",
      "Name of Earth Meteorite - string id - ID of Earth\n",
      "Meteorite - int nametype - string recclass - string\n",
      "mass - Mass of Earth Meteorite - float year - Year at which Earth\n",
      "Meteorite was hit - datetime format reclat - float recclong - float\n",
      "point coordinates - list of int\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Question 5 -\n",
      "Write a program to download the data from the given API link and then extract the following data with proper formatting\n",
      "\n",
      "\n",
      "Link - \n",
      "Note - Write proper code comments wherever needed for the code understanding\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Sample Data -\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Excepted Output Data Attributes -\n",
      "id - int url - string\n",
      "name - string season\n",
      "- int number - int\n",
      "type - string airdate -\n",
      "date format airtime -\n",
      "12-hour time format\n",
      "runtime - float\n",
      "average rating - float\n",
      "summary - string\n",
      "without html tags\n",
      "medium image link - string\n",
      "Original image link - string\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Question 6 -\n",
      "\n",
      "\n",
      "Using the data from Question 3, write code to analyze the data and answer the following questions Note 1. Draw plots to demonstrate the analysis for the following questions for better visualizations.\n",
      "Write code comments wherever required for code understanding\n",
      "\n",
      "\n",
      "\n",
      "Insights to be drawn -\n",
      "Get all Pokemons whose spawn rate is less than 5%\n",
      "Get all Pokemons that have less than 4 weaknesses\n",
      "Get all Pokemons that have no multipliers at all\n",
      "Get all Pokemons that do not have more than 2 evolutions\n",
      "Get all Pokemons whose spawn time is less than 300 seconds.\n",
      "Note - spawn time format is \"05:32â€, so assume â€œminute: secondâ€ format and perform the analysis.\n",
      "\n",
      "Get all Pokemon who have more than two types of capabilities\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Question 7 -\n",
      "Using the data from Question 4, write code to analyze the data and answer the following questions Note -\n",
      "Draw plots to demonstrate the analysis for the following questions for better visualizations\n",
      "\n",
      "Write code comments wherever required for code understanding\n",
      "\n",
      "\n",
      "\n",
      "Insights to be drawn -\n",
      "Get all the Earth meteorites that fell before the year 2000\n",
      "Get all the earth meteorites co-ordinates who fell before the year 1970\n",
      "Assuming that the mass of the earth meteorites was in kg, get all those whose mass was more than 10000kg\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Question 8 -\n",
      "Using the data from Question 5, write code the analyze the data and answer the following questions Note -\n",
      "Draw plots to demonstrate the analysis for the following questions and better visualizations\n",
      "\n",
      "Write code comments wherever required for code understanding\n",
      "\n",
      "\n",
      "\n",
      "Insights to be drawn -\n",
      "\n",
      "\tGet all the overall ratings for each season and using plots compare the ratings for all the seasons, like season 1 ratings, season 2, and so on.\n",
      "Get all the episode names, whose average rating is more than 8 for every season\n",
      "Get all the episode names that aired before May 2019\n",
      "Get the episode name from each season with the highest and lowest rating\n",
      "Get the summary for the most popular ( ratings ) episode in every season\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Question 9 -\n",
      "Write a program to read the data from the following link, perform data analysis and answer the following questions\n",
      "Note -\n",
      "Write code comments wherever required for code understanding\n",
      "\n",
      "Link - https://data.wa.gov/api/views/f6w7-q2d2/rows.csv?accessType=DOWNLOAD\n",
      "\n",
      "Insights to be drawn -\n",
      "\n",
      "Get all the cars and their types that do not qualify for clean alternative fuel vehicle\n",
      "Get all TESLA cars with the model year, and model type made in Bothell City.\n",
      "Get all the cars that have an electric range of more than 100, and were made after 2015\n",
      "Draw plots to show the distribution between city and electric vehicle type\n",
      "\n",
      "\n",
      "\n",
      "Question 10 -\n",
      "Write a program to count the number of verbs, nouns, pronouns, and adjectives in a given particular phrase or paragraph, and return their respective count as a dictionary.\n",
      "Note -\n",
      "Write code comments wherever required for code\n",
      "\n",
      "You have to write at least 2 additional test cases in which your program will run successfully and provide an explanation for the same.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Example Output -\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Statistics\n",
      "Total Marks: 120\n",
      "Each question 10 marks\n",
      "\n",
      "\n",
      "Q-1. A university wants to understand the relationship between the SAT scores of its applicants and their college GPA. They collect data on 500 students, including their SAT scores (out of 1600) and their college GPA (on a 4.0 scale). They find that the correlation coefficient between SAT scores and college GPA is 0.7. What does this correlation coefficient indicate about the relationship between SAT scores and college GPA?\n",
      "\n",
      "\n",
      "Q-2. Consider a dataset containing the heights (in centimeters) of 1000 individuals. The mean height is 170 cm with a standard deviation of 10 cm. The dataset is approximately normally distributed, and its skewness is approximately zero. Based on this information, answer the following questions:\n",
      "What percentage of individuals in the dataset have heights between 160 cm and 180 cm?\n",
      "If we randomly select 100 individuals from the dataset, what is the probability that their average height is greater than 175 cm?\n",
      "Assuming the dataset follows a normal distribution, what is the z-score corresponding to a height of 185 cm?\n",
      "We know that 5% of the dataset has heights below a certain value. What is the approximate height corresponding to this threshold?\n",
      "Calculate the coefficient of variation (CV) for the dataset.\n",
      "Calculate the skewness of the dataset and interpret the result.\n",
      "\n",
      "\n",
      "Q-3. Consider the â€˜Blood Pressure Beforeâ€™ and â€˜Blood Pressure Afterâ€™ columns from the data and calculate the following\n",
      "\n",
      "\n",
      "\n",
      "https://drive.google.com/file/d/1mCjtYHiX--mMUjicuaP2gH3k-SnFxt8Y/view?usp=share_\n",
      "\n",
      "Measure the dispersion in both and interpret the results.\n",
      "Calculate mean and 5% confidence interval and plot it in a graph\n",
      "Calculate the Mean absolute deviation and Standard deviation and interpret the results.\n",
      "Calculate the correlation coefficient and check the significance of it at 1% level of significance.\n",
      "\n",
      "\n",
      "Q-4. A group of 20 friends decide to play a game in which they each write a number between 1 and 20 on a slip of paper and put it into a hat. They then draw one slip of paper at random. What is the probability that the number on the slip of paper is a perfect square (i.e., 1, 4, 9, or 16)?\n",
      "\n",
      "Q-5. A certain city has two taxi companies: Company A has 80% of the taxis and Company B has 20% of the taxis. Company A's taxis have a 95% success rate for picking up passengers on time, while Company B's taxis have a 90% success rate. If a randomly selected taxi is late, what is the probability that it belongs to Company A?\n",
      "\n",
      "Q-6. A pharmaceutical company is developing a drug that is supposed to reduce blood pressure. They conduct a clinical trial with 100 patients and record their blood pressure before and after taking the drug. The company wants to know if the change in blood pressure follows a normal distribution.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Q-7. The equations of two lines of regression, obtained in a correlation analysis between variables X and Y are as follows:\n",
      "\n",
      "\n",
      "and . 2ð‘‹ + 3 âˆ’ 8 = 0 2ð‘Œ + ð‘‹ âˆ’ 5 = 0 The variance of ð‘‹ = 4 Find the\n",
      "Variance of Y\n",
      "Coefficient of determination of C and Y\n",
      "Standard error of estimate of X on Y and of Y on X.\n",
      "\n",
      "\n",
      "\n",
      "Q-8. The anxiety levels of 10 participants were measured before and after a new therapy. The scores are not normally distributed. Use the Wilcoxon signed-rank test to test whether the therapy had a significant effect on anxiety levels. The data is given below: Participant Before therapy After therapy Difference\n",
      "\n",
      "\n",
      "Q-9. Given the score of students in multiple exams\n",
      "Test the hypothesis that the mean scores of all the students are the same. If not, name the student with the highest score.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Q-10. A factory produces light bulbs, and the probability of a bulb being defective is 0.05. The factory produces a large batch of 500 light bulbs.\n",
      "What is the probability that exactly 20 bulbs are defective?\n",
      "What is the probability that at least 10 bulbs are defective?\n",
      "What is the probability that at max 15 bulbs are defective?\n",
      "On average, how many defective bulbs would you expect in a batch of 500?\n",
      "\n",
      "\n",
      "Q-11. Given the data of a feature contributing to different classes\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Check whether the distribution of all the classes are the same or not.\n",
      "Check for the equality of variance/\n",
      "Which amount LDA and QDA would perform better on this data for classification and why.\n",
      "Check the equality of mean for between all the classes.\n",
      "\n",
      "Q-12. A pharmaceutical company develops a new drug and wants to compare its effectiveness against a standard drug for treating a particular condition. They conduct a study with two groups: Group A receives the new drug, and Group B receives the standard drug. The company measures the improvement in a specific symptom for both groups after a 4-week treatment period.\n",
      "The company collects data from 30 patients in each group and calculates the mean improvement score and the standard deviation of improvement for each group. The mean improvement score for Group A is 2.5 with a standard deviation of 0.8, while the mean improvement score for Group B is 2.2 with a standard deviation of 0.6. Conduct a t-test to determine if there is a significant difference in the mean improvement scores between the two groups. Use a significance level of 0.05.\n",
      "Based on the t-test results, state whether the null hypothesis should be rejected or not. Provide a conclusion in the context of the study.\n",
      "\n",
      "\n",
      "\n",
      "Machine learning\n",
      "\n",
      "Total Marks: 210\n",
      "Each question 15 marks\n",
      "\n",
      "\n",
      "\n",
      "INTERMEDIATE QUESTIONS :\n",
      "Q-1. Imagine you have a dataset where you have different Instagram features like u sername , Caption , Hashtag , Followers , Time_Since_posted , and likes , now your task is to predict the number of likes and Time Since posted and the rest of the features are your input features. Now you have to build a model which can predict the number of likes and Time Since posted.\n",
      " This is the Dataset You can use this dataset for this question.\n",
      "\n",
      "\n",
      "Q-2. Imagine you have a dataset where you have different features like Age ,\n",
      "\n",
      "Gender , Height , Weight , BMI , and Blood Pressure and you have to classify the people into different classes like Normal , Overweight , Obesity , Underweight , and Extreme Obesity by using any 4 different classification algorithms. Now you have to build a model which can classify people into different classes.\n",
      " This is the Dataset You can use this dataset for this question.\n",
      "\n",
      "\n",
      "Q-3. Imagine you have a dataset where you have different categories of data, Now you need to find the most similar data to the given data by using any 4 different similarity algorithms. Now you have to build a model which can find the most similar data to the given data.\n",
      " This is the Dataset You can use this dataset for this question.\n",
      "\n",
      "\n",
      "Q-4. Imagine you working as a sale manager now you need to predict the Revenue and whether that particular revenue is on the weekend or not and find the Informational_Duration using the Ensemble learning algorithm\n",
      " This is the Dataset You can use this dataset for this question.\n",
      "\n",
      "\n",
      "Q-5. Uber is a taxi service provider as we know, we need to predict the high booking area using an Unsupervised algorithm and price for the location using a supervised algorithm and use some map function to display the data\n",
      " This is the Dataset You can use this dataset for this question.\n",
      "\n",
      "\n",
      "Q-6. Imagine you have a dataset where you have predicted loan Eligibility using any 4 different classification algorithms. Now you have to build a model which can predict loan Eligibility and you need to find the accuracy of the model and built-in docker and use some library to display that in frontend\n",
      " This is the Dataset You can use this dataset for this question.\n",
      "\n",
      "Q-7. Imagine you have a dataset where you need to predict the Genres of Music using\n",
      "an Unsupervised algorithm and you need to find the accuracy of the model, built-in docker, and use some library to display that in frontend\n",
      " This is the Dataset You can use this dataset for this question.\n",
      "\n",
      "\n",
      "Q-8. Quora question pair similarity, you need to find the Similarity between two questions by mapping the words in the questions using TF-IDF, and using a supervised Algorithm you need to find the similarity between the questions.\n",
      " This is the Dataset You can use this dataset for this question.\n",
      "\n",
      "\n",
      "Q-9. A cyber security agent wants to check the Microsoft Malware so need he came to you as a Machine learning Engineering with Data, You need to find the Malware\n",
      "\n",
      "using a supervised algorithm and you need to find the accuracy of the model.  This is the Dataset You can use this dataset for this question.\n",
      "\n",
      "1. An Ad- Agency analyzed a dataset of online ads and used a machine learning model to predict whether a user would click on an ad or not.\n",
      " This is the Dataset You can use this dataset for this question.\n",
      "\n",
      "\n",
      "\n",
      "Advance QUESTIONS :\n",
      "\n",
      "Q-1. A Social Media Influencer collected data on Facebook friend requests and used a supervised algorithm to predict whether a user would accept a friend request or not. t This is the Dataset You can use this dataset for this question. Note : Use only Dask and Use MLflow\n",
      "\n",
      "Q-2. A chemist had two chemical flasks labeled 0 and 1 which consist of two different chemicals. He extracted 3 features from these chemicals in order to distinguish between them, you provided the results derived by the chemicals and your task is to create a model that will label chemical 0 or 1 given its three features and built-in docker and use some library to display that in frontend.\n",
      "Note : Use only pyspark\n",
      "\n",
      " This is the Dataset You can use this dataset for this question.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Q- 3. A company wants to predict the sales of its product based on the money spent on different platforms for marketing. They want you to figure out how they can spend money on marketing in the future in such a way that they can increase their profit as much as possible built-in docker and use some library to display that in frontend  This is the Dataset You can use this dataset for this question. Note: Use only Dask\n",
      "\n",
      "\n",
      "\n",
      "Q-4. Take any 3 questions and deploy them to AWS using GitHub Actions and show a demo link\n",
      "\n",
      "\n",
      "Q-5. Take any 3 questions and deploy them to AWS using Circle-CI and show a demo link\n",
      "\n",
      "Deep Learning\n",
      "\n",
      "Total Marks: 100\n",
      "Each question 20 marks\n",
      "\n",
      "\n",
      "\n",
      "Question 1 -\n",
      "Implement 3 different CNN architectures with a comparison table for the MNSIT dataset using the Tensorflow library.\n",
      "Note -\n",
      "The model parameters for each architecture should not be more than 8000 parameters\n",
      "Code comments should be given for proper code understanding.\n",
      "The minimum accuracy for each accuracy should be at least 96%\n",
      "\n",
      "Question 2 -\n",
      "Implement 5 different CNN architectures with a comparison table for CIFAR 10 dataset using the PyTorch library\n",
      "Note -\n",
      "1. The model parameters for each architecture should not be more than 10000 parameters\n",
      "2 Code comments should be given for proper code understanding\n",
      "\n",
      "Question 3 -\n",
      "Train a Pure CNN with less than 10000 trainable parameters using the MNIST Dataset having minimum validation accuracy of 99.40%\n",
      "Note -\n",
      "Code comments should be given for proper code understanding.\n",
      "Implement in both PyTorch and Tensorflow respectively\n",
      "\n",
      "\n",
      "Question 4 -\n",
      "Design an end-to-end solution with diagrams for object detection use cases leveraging AWS cloud services and open-source tech\n",
      "Note -\n",
      "You need to use both AWS cloud services and open-source tech to design the entire solution\n",
      "The pipeline should consist of a data pipeline, ml pipeline, deployment pipeline, and inference pipeline.\n",
      "In the data pipeline, you would be designing how to get the data from external or existing sources and tech used for the same\n",
      "In the ml pipeline, you would be designing how to train the model, and what all algorithms, techniques, etc. would you be using. Again, tech used for the same 5.\n",
      "\n",
      "Since this is a deep learning project, the use of GPUs, and how effectively are you using them to optimize for cost and training time should also be taken into consideration.\n",
      "In the deployment pipeline, you would be designing how effectively and efficiently you are deploying the model in the cloud,\n",
      "In the inference pipeline, consider the cost of inference and its optimization\n",
      "\n",
      "\n",
      "\n",
      "related to computing resources and handling external traffic\n",
      "You can use any tool to design the architecture\n",
      "Do mention the pros and cons of your architecture and how much further it can be optimized and its tradeoffs.\n",
      "Do include a retraining approach as well.\n",
      "Try to include managed AWS resources for deep learning like AWS Textract, AWS Sagemaker, etc., and not just general-purpose compute resources like S3, EC2, etc. Try to mix the best of both services\n",
      "\n",
      "\n",
      "Question 5 -\n",
      "\n",
      "\n",
      "In Question 4, you have designed the architecture for an object detection use case leveraging AWS Cloud, similarly, here you will be designing for Document Classification use case leveraging Azure Cloud services.\n",
      "Note -\n",
      "1. Most of the points are the same as in Question 4, just cloud services will change\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Computer Vision\n",
      "\n",
      "Total Marks: 200\n",
      "Each question 20 marks\n",
      "\n",
      "\n",
      "\n",
      "Question 1 -\n",
      "Train a deep learning model which would classify the vegetables based on the images provided. The dataset can be accessed from the given link.\n",
      "\n",
      "Link-\n",
      "httpww.k\n",
      "\n",
      "Note -\n",
      "Use PyTorch as the framework for training model\n",
      "Use Distributed Parallel Training technique to optimize training time.\n",
      "Achieve an accuracy of at least 85% on the validation dataset.\n",
      "Use albumentations library for image transformation\n",
      "Use TensorBoard logging for visualizing training performance\n",
      "Use custom modular Python scripts to train model\n",
      "Only Jupyter notebooks will not be allowed\n",
      "Write code comments wherever needed for understanding\n",
      "\n",
      "\n",
      "Question 2 -\n",
      "From Question 1, you would get a trained model which would classify the vegetables based on the classes. You need to convert the trained model to ONNX format and achieve faster inference\n",
      "Note -\n",
      "There is no set inference time, but try to achieve as low an inference time as possible\n",
      "Create a web app to interact with the model, where the user can upload the image and get predictions\n",
      "Try to reduce the model size considerably so that inference time can be faster\n",
      "Use modular Python scripts to train and infer the model\n",
      "Only Jupyter notebooks will not be allowed\n",
      "Write code comments whenever needed for understanding\n",
      "\n",
      "\n",
      "Question 3 -\n",
      "Scrap the images from popular e-commerce websites for various product images sold on those websites. Your goal is to fetch the images from the website, create categories of different product classes and train a deep learning model to classify the same based on the user input.\n",
      "Note -\n",
      "1. You can use any framework of your choice like TensorFlow or PyTorch 2. You have to not use any pre-trained model, but instead create your own custom architecture and then train the model.\n",
      "Write code comments wherever needed for understanding\n",
      "Try to use little big dataset so that model can be generalized\n",
      "Write modular Python scripts to train and infer the model\n",
      "Only Jupyter Notebook will be not allowed\n",
      "Write code comments wherever needed for code understanding\n",
      "\n",
      "\n",
      "\n",
      "Question 4 -\n",
      "You have to train a custom YOLO V7 model on the dataset which is linked below. Your goal is to detect different products based on the given classes based on the user input\n",
      "\n",
      "Link - https://drive.google.com/file/d/1MEgDYJwO_PVVfAbyfjaRHXt7qoiBBHYt/view? usp=share_link\n",
      "\n",
      "Note -\n",
      "You have to use PyTorch implementation of YOLO V7\n",
      "The dataset consists of 102 classes with train, validation, and test images already in the respective folders.\n",
      "Labeling is already done, given with the dataset, so need for annotation\n",
      "Since the dataset is small, try to achieve at least an mAP of 85 5. Write modular Python scripts to train the model\n",
      "Write code comments wherever needed for understanding\n",
      "Computer Vision Assessment iNeuron 3\n",
      "Only Jupyter Notebook will not be allowed\n",
      "\n",
      "\n",
      "Question 5 -\n",
      "From Question 4, you would have a custom-trained YOLO model. Your goal is to need to convert the model to ONNX format and reduce the inference time.\n",
      "\n",
      "Note -\n",
      "Reduce the inference time to as much as possible\n",
      "Try to reduce the model size by using techniques like Quantization, etc 3. Create a web app for users to interact with your model where users can upload images and get predictions.\n",
      "Write modular Python scripts to infer the model.\n",
      "\n",
      "Only Jupyter notebooks are not allowed.\n",
      "Write code comments wherever needed for code understanding\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Question 6 -\n",
      "You have to train a custom segmentation model based on Detectron 2 framework. Your goal is to segment the given images based on the user input into the different classes\n",
      "\n",
      "Link -\n",
      "httpww.k tion/data\n",
      "\n",
      "Note -\n",
      "For this, only the Jupyter Notebook is fine\n",
      "Labels are in COCO format.\n",
      "Write code comments wherever needed for understanding\n",
      "\n",
      "\n",
      "\n",
      "Question 7 -\n",
      "From Question 6, you would have custom trained segmentation model. Your goal is to reduce the model inference time\n",
      "\n",
      "Note -\n",
      "Reduce inference time to as much as possible\n",
      "Create a web app for users to interact with your model where they can upload images and get predictions\n",
      "Write code comments wherever needed for code understanding.\n",
      "\n",
      "\n",
      "Question 8 -\n",
      "You have to train a custom object detection model based on DETR (Detection Transformer)\n",
      "\n",
      "Link - httpww.k\n",
      "\n",
      "Note -\n",
      "You need to use HuggingFace PyTorch as the framework\n",
      "The dataset is about detecting football players from the images provided\n",
      "Data Annotations are already in COCO format.\n",
      "Write custom Python scripts for training.\n",
      "\n",
      "Write code comments wherever needed for code understanding\n",
      "Only Jupyter Notebooks are not allowed\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Question 9 -\n",
      "From Question 8, you would have a custom object detection model\n",
      "Note -\n",
      "Try to reduce the model size using quantization\n",
      "Create a web app where the users can interact with your model\n",
      "Write modular Python script for model inference\n",
      "Only Jupyter Notebooks are not allowed\n",
      "Write code comments wherever needed for code understanding\n",
      "\n",
      "\n",
      "Question 10 -\n",
      "From all the questions from 1 to 9, take any image classification model, object model detection model, and image segmentation model and deploy it in the cloud Note -\n",
      "1. Deployment of all 3 different models should be AWS, Azure, and GCP 2. A video demo of the application working in the cloud should be good enough 3. Containerization of all 3 applications is important and should be pushed to Docker Hub\n",
      "Computer Vision Assessment iNeuron 5\n",
      "4. CI-CD pipelines using GitHub actions that would deploy the models in all 3 clouds are mandatory.\n",
      "\n",
      "Natural Language Processing\n",
      "\n",
      "Total Marks: 200\n",
      "Each question 20 marks\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Q-1. Take any YouTube videos link and your task is to extract the comments from that videos and store it in a csv file and then you need define what is most demanding topic in that videos comment section.\n",
      "\n",
      "\n",
      "Q-2. Take any pdf and your task is to extract the text from that pdf and store it in a csv file and then you need to find the most repeated word in that pdf.\n",
      "\n",
      "Q-3. from question 2, As you got the CSV and now you need perform key word extraction from that csv file and do the Topic modeling\n",
      "\n",
      "Q-4. Take any text file and now your task is to Text Summarization without using hugging transformer library\n",
      "\n",
      "Q-5. Now you need build your own language detection with the fast Text model by Facebook and\n",
      "\n",
      "Q-6. Generate research papers titles using Bert model and containerize the application and push to public docker hub\n",
      "\n",
      "Q-7. Now you need to build your own chatbot using the seq2seq model of Amazon website by scrape the website and containerize the application and push to public docker hub\n",
      "\n",
      "Q-8. Take a any own dataset and build a knowledge bot using Llama model.\n",
      "\n",
      "Q-9. Using wisher you need transcribe any audio file and then you need to convert that audio file into text file and now convert that text file into audio file of different language.\n",
      "\n",
      "Q-10. Build a whole End- End api and deploy it on Heroku /railways so the task is that you need build a Auto-Correction of text using NLP\n",
      "Note: only Jupyter notebook is not allowed from 5th question\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "â† Submission Process â†’\n",
      "There are Two Types of Questions Theory based Question and Project-based (where you actually have to code)\n",
      "\n",
      "First of all, You have to create an Google doc, where you will add answers of all the questions\n",
      "\n",
      "If you are attempting a question in which you have to write code, so create a repo push your code to repo and copy the link of repo and add it into docs as shown below\n",
      "Eg. Answer. 6 Python - > GitHub repo link Note:\n",
      "If you are building any End to end project try to write code in .py file\n",
      "If you are only analyzing or doing EDA use .ipynb file\n",
      "\n",
      "If you are attempting a theory-based question then you have to add the answer in the same google docs as it's\n",
      "\n",
      "\n",
      "Then submit that final link (google doc link which has all the answers)\n"
     ]
    }
   ],
   "source": [
    "# Example\n",
    "from docx import Document\n",
    "doc = Document(\"Data Science.docx\") # Path of the Docx file\n",
    "# Access the list of paragraphs\n",
    "paragraphs = doc.paragraphs\n",
    "\n",
    "# Iterate over the paragraphs\n",
    "for paragraph in paragraphs:\n",
    "    print(paragraph.text) # Prints the text in the paragraph\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5161abea",
   "metadata": {},
   "source": [
    "# 8. What type of object has bold, underline, italic, strike, and outline variables?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146f8183",
   "metadata": {},
   "source": [
    "<b>Ans: </b>Run object has bold, underline, italic, strike, and outline variables. The text in a Word document is more than just a string. It has font, size, color, and other styling information associated with it.\n",
    "\n",
    "A style in Word is a collection of these attributes. A Run object is a contiguous run of text with the same style. A new Run object is needed whenever the text style changes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5acc02",
   "metadata": {},
   "source": [
    "# 9. What is the difference between False, True, and None for the bold variable?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac1fed22",
   "metadata": {},
   "outputs": [],
   "source": [
    "bold = True  # Style Set to Bold\n",
    "bold = False # Style Not Set to Bold\n",
    "bold = None # Style is Not Applicable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d4e8d74",
   "metadata": {},
   "source": [
    "# 10. How do you create a Document object for a new Word document?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e93b68f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example\n",
    "from docx import Document\n",
    "document = Document()\n",
    "document.add_paragraph(\"iNeuron Full Stack DataScience Course\")\n",
    "document.save('mydocument.docx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfaf1e73",
   "metadata": {},
   "source": [
    "# 11. How do you add a paragraph with the text &#39;Hello, there!&#39; to a Document object stored in a variable named doc?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "68e0380f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example \n",
    "from docx import Document\n",
    "doc = Document()\n",
    "doc.add_paragraph('Hello, there!')\n",
    "doc.save('hello.docx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09008358",
   "metadata": {},
   "source": [
    "# 12. What integers represent the levels of headings available in Word documents?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6d43b1",
   "metadata": {},
   "source": [
    "<b>Ans: </b> The levels for a heading in a word document can be specified by using the level attribute inside the add_heading method. There are a total of 5 levels statring for 0 t0 4. where level 0 makes a headline with the horizontal line below the text, whereas the heading level 1 is the main heading. Similarly, the other headings are sub-heading with their's font-sizes in decreasing order."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
